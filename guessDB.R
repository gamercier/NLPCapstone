# Capstone Project
# File: guessDB.R
#   builds the guess database
#   Loads Corpus, cleans it, generates DTM, DFM (frequency), DSM (score)
#   Loads Corpus (files created by fixRawData.R)
#     proc/unix.blogs.txt, proc/unix.news.txt, proc/unix.twitter.txt

print("Started script: guessDB.R")
# Got to project directory and load tools
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
setwd(prj.dir)
print(paste("Current directory: ",getwd()))

# load resources
source("nlpTools.R")

#Switch to processed corpus directory
source("toProcCorpusDir.R")

# proc.corpus.dir set in toProcCorpusDir.R
text.files <- c("unix.blogs.txt", "unix.news.txt", "unix.twitter.txt")
print(paste("Processed Corpus Directory Files: ",paste0(text.files,collapse=", ")))

# select only a fraction of the processed corpus
# In this case 5% of the original data for each file.
# s.text is a list with each element one sample of the corpus
# the corpus consists of 3 files of text.
s.text <- lapply(0.05,sampleText,text.files)

# Building corpus from sample files generated by sampleText function.
corpus <- lapply(s.text,buildCorpus)

# release some memory
rm(s.text)

# Structure of corpus:
# This is a list. Each element corresponds to a sample.
# Each sample is an list containing an object, one for each text file (a document)
# The object contains two data members, content and meta, for the text file.
#
# For example, to access the text of text file 2 in sample 1:
#   corpus[[1]][2]$content
#
# The content is a character vector with multiple entries with multiple
# lines of text per entry in the vector.

# Perform operations on the corpus
# First clean it.
clean.corpus <- lapply(corpus,purify.corpus)
#  put in file names
for(j in seq(clean.corpus)){
  for(k in seq(clean.corpus[[j]])){ 
    meta(clean.corpus[[j]][[k]],"id") <- text.files[k]
  }
}

print("Saving raw corpus and clean corpus.")
if(file.exists("corpus.r")){
  file.remove("corpus.r")
}
save(corpus,clean.corpus,file="corpus.r")
print("Finished saving corpus stuff.")

# Second, Generate DTMS for clean corpus
print("Generating DTMS for clean corpus.")
dtms <- lapply(clean.corpus,buildDTM) # using default 4-gram as maximum
for(k in seq_along(clean.corpus)){
  names(dtms[[k]])<- c("unigram","bigram","trigram","quadgram")
}

print("Saving DTMS.")
if(file.exists("dbdtms.r")){
  file.remove("dbdtms.r")
}
save(dtms,file="dbdtms.r")
print("Finished saving DTMS.")

# Computing frequencies

# dtms is a list with one element per sample set. Each element has
# DTM for unigram ... quadgram (or higher depending on max.ngram)
print("Computing frequencies and sorting in decreasing order...")
freq.db <- lapply(dtms,dtm2freq)

# Generating additional data

#### NOTE ####
# Structure of object freq.db is a list that contains sublists, one per n-gram.
# Each sublist contains a subsublist with only one member, a named vector that contains
# the frequencies. The names are the n-grams.

#    SORT - already done
#    COLLECT sorted ngrams
ngrams.db <- lapply(freq.db,function(x) lapply(x,names))

#    COLLECT the base, or the ngram minus the last word; nonsense for unigrams
bases.db <- lapply(ngrams.db,
        function(x) { lapply(x[-1], function(x) unlist(dropLastWord(x))) } )

#    GET number of ngrams for each N, as a list, (includes repetitions)
N.ngrams <- lapply(freq.db, function(x) lapply(x,sum))

#    GET number of ngrams for each N, as a list, (no repetitions)
unique.N.ngrams <- lapply(ngrams.db,function(x) lapply(x,length))

print("Saving frequencies, etc...")
if(file.exists("dbfreq.r")){
  file.remove("dbfreq.r")
}
save(freq.db,ngrams.db,bases.db,N.ngrams,unique.N.ngrams,file="dbfreq.r")
print("Finished saving freq.db stuff.")


# Define SCORING FUNCTION. Based on Stupid Back Off
#    score(ngram) = counts(ngram)/counts(ngram with first word dropped) if n >1
#    score(1gram) = counts(1gram)/(total number of 1grams (not unique 1grams))
#For stupid back up implementation:
#http://stackoverflow.com/questions/16383194/stupid-backoff-implementation-clarification

# NOTE: Computations here assume that for each sample,
#       the freq.db is ordered as unigram, bigram, trigram, quadgram...
#

print("Computing ngram scores for the database.")
scores.db <- lapply(freq.db,score.sbackoff) # computes scores for each sample
print("Done computing scores.")

print("Saving scores database in *dbScores.r*")
save(scores.db, ngrams.db, bases.db, file="dbScores.r")
print("Finished saving scores database!")

### END
print("Returning to main directory!")
setwd(prj.dir)
print(paste("Current directory: ",getwd()))

print("Completed guessDB.R")
