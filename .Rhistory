library(stringr)
library(devtools)
install_github("yihui/printr")
library(wordcloud)
library(tm)
library(stringi)
library(tm)
vignette(tm)
vignette("tm")
getwd()
print(paste("Using directory",getwd()))
getwd()
# Capstone Project
# File: makeCorpus.R
#   Reads files created by fixRawData.R
#        proc/unix.blogs.txt, proc/unix.news.txt, proc/unix.twitter.txt
#   Generates the Corpus object, and cleans it.
#   Saves the cleaned corpus
print("Started script: makeCorpus.R")
# Got to project directory and load tools
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
setwd(prj.dir)
print(paste("Current directory: ",getwd()))
# load resources
source("nlpTools.R")
print("Loaded tools.")
#Switch to processed corpus directory
source("toProcCorpusDir.R")
print(paste("Switched to diretory",getwd()))
# proc.corpus.dir set in toProcCorpusDir.R
text.files <- c("unix.blogs.txt", "unix.news.txt", "unix.twitter.txt")
print(paste("Processed Corpus Directory Files: ",paste0(text.files,collapse=", ")))
# select only a fraction of the processed corpus
# In this case % of the original data for each file.
# s.text is a list with each element one sample of the corpus
# the corpus consists of 3 files of text.
pcent <- c(0.01,0.05,0.10)
s.text <- lapply(pcent,sampleText,text.files)
# Building corpus from sample files generated by sampleText function.
corpus <- lapply(s.text,buildCorpus)
# release some memory
rm(s.text)
# Perform operations on the corpus
# First clean it.
clean.corpus <- lapply(corpus,purify.corpus,
toASCII=TRUE,collapseContractions=TRUE,
collapseHyphens=TRUE,removeStopWords=FALSE,stemWords=FALSE)
ls
toSpace("x-mas",HYPHEN.PAT,perl=TRUE)
toNone("x-mas",HYPHEN.PAT,perl=TRUE)
toNone("199-200",HYPHEN.PAT,perl=TRUE)
toSpace("given that it --- 200 and 9",HYPHEN.PAT,perl=TRUE)
toSpace("given that it --- 200 and 9",EMDASH.PAT,perl=TRUE)
ENDASH.PAT <- "(?<=[a-zA-Z0-9 ])--(?=[a-zA-Z0-9 ])" # true endash is outside ASCII code
EMDASH.PAT <- "(?<=[a-zA-Z0-9 ])---(?=[a-zA-Z0-9 ])" # true emdash is outside ASCII code
toSpace("given that it --- 200 and 9",EMDASH.PAT,perl=TRUE)
source('~/git/NLPCapstone/nlpTools.R')
clean.corpus <- lapply(corpus,purify.corpus,
toASCII=TRUE,collapseContractions=TRUE,
collapseHyphens=TRUE,removeStopWords=FALSE,stemWords=FALSE)
pcent <- c(0.01,0.05,0.10)
s.text <- lapply(pcent,sampleText,text.files)
# Building corpus from sample files generated by sampleText function.
corpus <- lapply(s.text,buildCorpus)
# release some memory
rm(s.text)
