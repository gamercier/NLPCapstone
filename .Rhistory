# Capstone Project
# file trimDB.R
# Takes the scores database (with associated ngrams and bases) and trims it
# Strategy 1: Drops cases where ngram frequency is 1 (except for unigrams)
#     This generate the short list
# Strategy 2: Keeps the 3 top scoring ngrams that have the same
#             (n-1)gram at a begining
#     This generates the minimal list
# Strategy 3: keep unigrams that cover 90% of the corpus. NOT GOOD COMMENTED OUT
# Change directory to location of project directory and load tools
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
setwd(prj.dir)
source("nlpTools.R")
# Change directory to corpus directory
download.dir <- "nlpData.dir"; sub.dir <- "final"; proc.corpus.dir <- "proc"
proc.corpus.dir <- file.path(prj.dir,download.dir,sub.dir,proc.corpus.dir)
setwd(proc.corpus.dir)
# Change directory to version of database we want
try.dir <- file.path(proc.corpus.dir,"try_02")  # doing second try
setwd(try.dir)
print(paste("Current directory: ",getwd()))
# Strategy 4 - Do pruning in DTM instead
# Explore the frequency of frequencies:
load("dbfreq.r")
freqDB <- freq.db[[1]] # take the first sample
load("dbScores.r")
scoresDB <- scores.db[[1]] # take the first sample from full score
basesDB <- bases.db[[1]]
ngramsDB <- ngrams.db[[1]]
ffDB<- lapply(freqDB,freq2ff)
lapply(ffDB,head,n=5)
dtmDB
load("dbdtms.r")
library(tm)
dtmDB <- dtms[[1]] # take the first sample
dtmDB
dtmDB.s10 <- list()
dtmDB.s10$unigram <- dtmDB$unigram
dtmDB.s10
dtmDB.s10[2:4] <- lapply(dtmDB[2:4],removeSparseTerms,0.1)
dtmDB.s10
names(dtmDB.s10) <- c(unigram,bigram,trigram,quadgram)
names(dtmDB.s10) <- c("unigram","bigram","trigram","quadgram")
dtmDB.s10
dtmDB
dtmDB.s10[2:4] <- lapply(dtmDB[2:4],removeSparseTerms,0.33)
names(dtmDB.s10) <- c("unigram","bigram","trigram","quadgram")
dtmDB.s10
freqDB <- dtm2freq(dtmDB.s10)
str(freqDB)
lengths(freqDB
)
scoresDB <- scores.sbackoff(freqDB)
scoresDB <- score.sbackoff(freqDB)
str(scoresDB)
ngramsDB <- lapply(scoresDB,names)
str(ngramsDB)
basesDB <- lapply(ngramsDB,dropLastWord)
str(basesDB)
basesDB <- lapply(ngramsDB,function(x) unlist(dropLastWord(x)))
str(basesDB)
str(ngramsDB)
basesDB <- lapply(ngramsDB[2:4],function(x) unlist(dropLastWord(x)))
str(basesDB)
dtmDB.sp33 <- list()
dtmDB.sp33$unigram <- dtmDB$unigram
dtmDB.sp33[2:4] <- lapply(dtmDB[2:4],removeSparseTerms,0.33)
names(dtmDB.sp33) <- c("unigram","bigram","trigram","quadgram")
freqDB <- dtm2freq(dtmDB.sp33)
scoresDB <- score.sbackoff(freqDB)
ngramsDB <- lapply(scoresDB,names)
basesDB <- lapply(ngramsDB[2:4],function(x) unlist(dropLastWord(x)))
freq.db.sp33 <- list(freqDB)
scores.db.sp33 <- list(scoresDB)
ngrams.db.sp33 <- list(ngramsDB)
bases.db.sp33 <- list(basesDB)
save(freq.db.sp33,file="dbfreq_Sp33.r")
save(scores.db.sp33,ngrams.db.sp33,bases.db.sp33,file="dbSp33Scores.r")
scoresDB <- scores.db.sp33[[1]] ; TOPUNI.SCORES <- scoresDB$unigram[1:3]
ngramsDB <- ngrams.db.sp33[[1]]
basesDB <- bases.db.sp33[[1]]
# Change directory to location of project directory and load tools
prj.dir <- file.path(Sys.getenv("HOME"),"git","NLPCapstone")
setwd(prj.dir)
getwd()
print("Loading tools!")
source("nlpTools.R")
print("Data for testing!")
# Load data for testing
if(file.exists(file.path(prj.dir,"test_quads.r"))){
load(file.path(prj.dir,"test_quads.r"))
print("Loaded quadgrams for testing.")
} else {
load(file.path(prj.dir,"quads.r"))
n.sample <- 1000
test.sample <- quads[sample.int(length(quads),n.sample)]
save(test.sample,file=file.path(prj.dir,"test_quads.r"))
print("Built and saved new set of quadgrams for testing")
}
# MAIN FUNCTION
guess.sb <- function(trigram,scores=scoresDB,ngrams=ngramsDB,bases=basesDB){
ngram <- trigram
n <- 3
hits <- c((0.4^3)*TOPUNI.SCORES)
while(n > 0) {
if(ngram %in% ngrams[[n]]){
hits <-
c(hits,((0.4)^(3-n))*scores[[(n+1)]]
[ ngrams[[(n+1)]][ ngram == bases[[(n)]] ] ]) # basesDB is offset down by 1
}
# back off
ngram <- dropFirstWord(ngram)
n <- n-1
}
scores.sorted <- sort(hits,decreasing=TRUE)
scores.sorted <- scores.sorted[unique(names(scores.sorted))][1:3]
words.sorted <- toWords(names(scores.sorted))
guesses <- sapply(words.sorted, function(x) x[length(x)] )
return(data.frame(guess=guesses,scores=scores.sorted))
}
# automating testing
testing <- function(test.s){
hit <- function(x){
guesses <- guess.sb(unlist(dropLastWord(x)))$guess
if(unlist(getLastWord(x)) %in% guesses){
return(TRUE)
} else {
return(FALSE)
}
}
test.f <- sapply(test.s,hit)
return(test.f)
}
str(scoresDB)
results <- testing(test.sample)
print(paste("Hits: ",sum(results)," out of ",length(results)))
